{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import cv2\n",
    "from cellpose import plot\n",
    "import os\n",
    "from skimage.measure import label, regionprops, regionprops_table\n",
    "from skimage.color import label2rgb\n",
    "import pandas as pd\n",
    "import glob\n",
    "import pathlib\n",
    "import seaborn as sns\n",
    "from pip._internal.cli.progress_bars import get_download_progress_renderer\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "def pad_array_with_nans(arr, mid_idx, padd_arr_len=41):\n",
    "    \"\"\"\n",
    "    Pads an array with NaN values around \"start_idx\" and \"end_idx\" index\n",
    "    \"\"\"\n",
    "    start_idx = max(padd_arr_len//2 - mid_idx, 0)\n",
    "    # if left side doesn't fit cut and shift mid_idx\n",
    "    if mid_idx >= padd_arr_len//2: \n",
    "        left_shift = mid_idx - padd_arr_len//2\n",
    "        arr = arr[left_shift:]\n",
    "        mid_idx = mid_idx - left_shift\n",
    "\n",
    "    end_idx = min(padd_arr_len//2 + (len(arr) - mid_idx), padd_arr_len)\n",
    "    if end_idx == padd_arr_len:\n",
    "        arr = arr[:padd_arr_len-start_idx]\n",
    "    \n",
    "    padded_arr = np.full(padd_arr_len, np.nan)\n",
    "    padded_arr[start_idx:end_idx] = arr\n",
    "    return padded_arr\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def arrays_average_std(arrays):\n",
    "    \"\"\"\n",
    "    Calculates average and standard deviation of multiple equally sized numpy arrays with NaNs using a loop.\n",
    "\n",
    "    Parameters:\n",
    "    arrays (list): List of numpy arrays.\n",
    "\n",
    "    Returns:\n",
    "    result (tuple): Tuple of average and standard deviation arrays for each index, with NaNs where these statistics cannot be calculated.\n",
    "    \"\"\"\n",
    "    # Replace NaNs with zeros temporarily to calculate sum and count\n",
    "    sums = np.nan_to_num(arrays[0])\n",
    "    counts = np.array(~np.isnan(arrays[0]), dtype=int)\n",
    "    for i in range(1, len(arrays)):\n",
    "        sums += np.nan_to_num(arrays[i])\n",
    "        counts += np.array(~np.isnan(arrays[i]), dtype=int)\n",
    "\n",
    "    # Calculate average and std of each element\n",
    "    result_avg = np.empty([arrays[0].size])\n",
    "    result_std = np.empty([arrays[0].size])\n",
    "    for i in range(arrays[0].size):\n",
    "        # Calculate average and std if all elements are not NaN, otherwise set them to NaN\n",
    "        if np.all(np.isnan([arr[i] for arr in arrays])):\n",
    "            result_avg[i] = np.nan\n",
    "            result_std[i] = np.nan\n",
    "        else:\n",
    "            temp_sum = np.sum([np.nan_to_num(arr[i]) for arr in arrays])\n",
    "            temp_count = np.sum(~np.isnan([arr[i] for arr in arrays]))\n",
    "            avg = temp_sum / temp_count\n",
    "            std = np.sqrt(np.sum([(np.nan_to_num(arr[i]) - avg) ** 2 for arr in arrays if not np.isnan(arr[i])]) / (temp_count - 1))\n",
    "            result_avg[i] = avg\n",
    "            result_std[i] = std\n",
    "\n",
    "    return result_avg, result_std\n",
    "\n",
    "def arrays_average_sem(arrays):\n",
    "    '''Parameters:\n",
    "    arrays (list): List of numpy arrays.\n",
    "\n",
    "    Returns:\n",
    "    result (tuple): Tuple of average and standard error of the mean arrays for each index, with NaNs where these statistics cannot be calculated.\n",
    "    '''\n",
    "    # Replace NaNs with zeros temporarily to calculate sum and count\n",
    "    sums = np.nan_to_num(arrays[0])\n",
    "    counts = np.array(~np.isnan(arrays[0]), dtype=int)\n",
    "    for i in range(1, len(arrays)):\n",
    "        sums += np.nan_to_num(arrays[i])\n",
    "        counts += np.array(~np.isnan(arrays[i]), dtype=int)\n",
    "\n",
    "    # Calculate average and SEM of each element\n",
    "    result_avg = np.empty([arrays[0].size])\n",
    "    result_sem = np.empty([arrays[0].size])\n",
    "    for i in range(arrays[0].size):\n",
    "        # Calculate average and SEM if all elements are not NaN, otherwise set them to NaN\n",
    "        if np.all(np.isnan([arr[i] for arr in arrays])):\n",
    "            result_avg[i] = np.nan\n",
    "            result_sem[i] = np.nan\n",
    "        else:\n",
    "            temp_sum = np.sum([np.nan_to_num(arr[i]) for arr in arrays])\n",
    "            temp_count = np.sum(~np.isnan([arr[i] for arr in arrays]))\n",
    "            avg = temp_sum / temp_count\n",
    "            sem = np.sqrt(np.sum([(np.nan_to_num(arr[i]) - avg) ** 2 for arr in arrays if not np.isnan(arr[i])]) / (temp_count * (temp_count - 1)))\n",
    "            result_avg[i] = avg\n",
    "            result_sem[i] = sem\n",
    "\n",
    "    return result_avg, result_sem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import CSV\n",
    "CSV with cell trajectrories created as follows:\n",
    "- Cellpose segmentation\n",
    "- TrackMate tracking of segmented images\n",
    "- Random Forest rough segmentation of deviding cells\n",
    "- Detection of division events with `nematics\\journals\\cell_divisions_cellpose_TrackMate.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_track_len = 50\n",
    "track_df1 = pd.read_csv(r\"C:\\Users\\victo\\Downloads\\SB_lab\\HBEC\\s2(120-919)\\Tracking\\spots_100_500_wdivs.csv\")\n",
    "track_df1['count'] = track_df1.groupby('TRACK_ID')['TRACK_ID'].transform('count')\n",
    "track_df2 = track_df1.loc[track_df1['count']>min_track_len]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate averge dynamics of `PARAMETER` for deviding cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AREA (400,)\n",
      "PERIMETER (400,)\n",
      "SHAPE_INDEX (400,)\n",
      "CIRCULARITY (400,)\n",
      "RADIUS (400,)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "tracks_all = track_df2[\"TRACK_ID\"][track_df2['T0']==1].unique()\n",
    "\n",
    "params = ['AREA', 'PERIMETER','SHAPE_INDEX', 'CIRCULARITY', 'RADIUS' , #'ELLIPSE_MAJOR', 'ELLIPSE_ASPECTRATIO'     \n",
    "# 'RADIUS', 'ELLIPSE_X0', 'ELLIPSE_Y0', 'ELLIPSE_MAJOR', 'ELLIPSE_MINOR', \n",
    "# 'ELLIPSE_THETA', 'ELLIPSE_ASPECTRATIO', 'AREA', 'PERIMETER',\n",
    "# 'CIRCULARITY', 'SOLIDITY', 'SHAPE_INDEX', 'DIVIDING'\n",
    "]\n",
    "PARAM = 'ELLIPSE_MINOR'\n",
    "\n",
    "\n",
    "frame2hr = 1/12\n",
    "padd_arr_len = 400\n",
    "\n",
    "data_dict = {}\n",
    "\n",
    "plt.figure(PARAM)\n",
    "fig, axs  = plt.subplots(1,len(params), num=PARAM)\n",
    "axs = axs.ravel()\n",
    "\n",
    "for ax,PARAM in zip(axs, params):\n",
    "    param_arr = []\n",
    "    for tid in tracks_all[:5000:10]:\n",
    "        div_idx = track_df2[PARAM][track_df2[\"TRACK_ID\"]==tid].index    \n",
    "        param_val = track_df2[PARAM][div_idx].rolling(window=5).mean()\n",
    "        # param_val = np.diff(param_val)\n",
    "        t0 = track_df2[\"T0\"][div_idx].values.astype(int)\n",
    "        \n",
    "        if not any(t0[0:3]):\n",
    "            t0_val = t0\n",
    "            # print(len(t0))\n",
    "\n",
    "            mid_idx = int(np.where(t0>0)[0])\n",
    "            #  collect param_val arrays for averaging\n",
    "            param_arr.append(pad_array_with_nans(param_val, mid_idx, padd_arr_len=padd_arr_len))            \n",
    "\n",
    "            # print(np.where(t0>0)[0])\n",
    "            # ax.plot(np.arange(len(param_val)) - mid_idx, param_val, alpha=.03, linewidth=3, color='r')\n",
    "            # ax.plot(np.arange(len(param_val)), param_val, alpha=.03, linewidth=3, color='r')\n",
    "            \n",
    "    # param_ave, param_std = arrays_average_std(param_arr) #standart diviation\n",
    "    param_ave, param_std = arrays_average_sem(param_arr) #standart mean error\n",
    "\n",
    "    print(PARAM, param_ave.shape)\n",
    "    x = np.arange(len(param_ave))-padd_arr_len//2\n",
    "    x = x * frame2hr\n",
    "    ax.axvline(x=0, color='red', linestyle='--', linewidth=3, alpha=0.3)\n",
    "    ax.plot(x, param_ave, alpha=.3, linewidth=3, color='b')\n",
    "    ax.fill_between(x, param_ave - param_std, param_ave + param_std, color='blue', alpha=0.2)\n",
    "    ax.set_xlabel(\"$hours$\") \n",
    "    ax.set_title(PARAM)\n",
    "    ax.set_xlim([-padd_arr_len//2 * frame2hr, padd_arr_len//2 * frame2hr])\n",
    "    # ax.set_ylim([param_val.min(),param_val.max()])\n",
    "    data_dict[PARAM] = {\"_ave\": param_ave, \"std\": param_std}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to file (`save_path`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r\"C:\\Users\\victo\\Downloads\\SB_lab\\HBEC\\s2(120-919)\\Tracking\\spots_100_500_wdivs_division_dynamics\"+str(min_track_len)+\".pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path, 'wb') as f:\n",
    "    pickle.dump(data_dict, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load file (`save_path`) and plot all `PARAMS`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\victo\\\\Downloads\\\\SB_lab\\\\HBEC\\\\s2(120-919)\\\\Tracking\\\\spots_100_500_wdivs_division_dynamics120.pkl',\n",
       " 'C:\\\\Users\\\\victo\\\\Downloads\\\\SB_lab\\\\HBEC\\\\s2(120-919)\\\\Tracking\\\\spots_100_500_wdivs_division_dynamics200.pkl',\n",
       " 'C:\\\\Users\\\\victo\\\\Downloads\\\\SB_lab\\\\HBEC\\\\s2(120-919)\\\\Tracking\\\\spots_100_500_wdivs_division_dynamics50.pkl',\n",
       " 'C:\\\\Users\\\\victo\\\\Downloads\\\\SB_lab\\\\HBEC\\\\s2(120-919)\\\\Tracking\\\\spots_100_500_wdivs_division_dynamics80.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_averages = glob.glob(r\"C:\\Users\\victo\\Downloads\\SB_lab\\HBEC\\s2(120-919)\\Tracking\\spots_100_500_wdivs_division_dynamics*.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['_ave', 'std'])\n"
     ]
    }
   ],
   "source": [
    "saved_averages = \n",
    "with open(save_path, 'rb') as f:\n",
    "    data_dict1 = pickle.load(f)\n",
    "\n",
    "fig, axs  = plt.subplots(1,len(data_dict1.keys()), num=\"1\")\n",
    "axs = axs.ravel()\n",
    "print(data_dict1[\"AREA\"].keys())\n",
    "\n",
    "frame2hr = 1/12\n",
    "for ax,param_name in zip(axs, data_dict1):\n",
    "    param_ave = data_dict1[param_name][\"_ave\"]\n",
    "    param_std = data_dict1[param_name][\"std\"]\n",
    "\n",
    "    x = np.arange(len(param_ave))-len(param_ave)//2\n",
    "    x = x * frame2hr\n",
    "    ax.axvline(x=0, color='red', linestyle='--', linewidth=3, alpha=0.3)\n",
    "    ax.plot(x, param_ave, alpha=.3, linewidth=3, color='b')\n",
    "    ax.fill_between(x, param_ave - param_std, param_ave + param_std, color='blue', alpha=0.2)\n",
    "    ax.set_xlabel(\"$hours$\") \n",
    "    ax.set_title(param_name)\n",
    "    ax.set_xlim([-padd_arr_len//2 * frame2hr, padd_arr_len//2 * frame2hr])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellpose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7cf831c40117d68663987ffaca5e7a78b351d1bd9696323579ea0b5ef7b310a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
